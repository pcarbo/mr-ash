---
title: mr.ash vs. lasso
author: Peter Carbonetto
date: June 18, 2020
site: workflowr::wflow_site
output: workflowr::wflow_html
---

*Add text here giving overview of analysis, and results.*

```{r knitr, echo=FALSE}
knitr::opts_chunk$set(comment = "#",results = "hold",collapse = TRUE,
                      fig.align = "center",dpi = 140)
```

Analysis settings: number of simulations (ns), number of samples in
training set (n), number of simulated variables (p), maximum number of
variables with an effect on the continuous outcome (p1), proportion of
variance in the outcome explained by the variables (pve).

```{r params}
ns  <- 100
n   <- 500
p   <- 1000
p1  <- 500
pve <- 0.95
```

*Briefly explain here how these packages are being used.*

```{r initial-setup}
library(glmnet)
library(mr.ash.alpha)
library(ggplot2)
library(cowplot)
source("../code/functions_for_mr_ash_vs_lasso.R")
```

*Add text here.*

```{r init-rsme}
res <- data.frame(p1          = round(seq(1,p1,length.out = ns)),
                  rmse.true   = rep(0,ns),
                  rmse.min    = rep(0,ns),
                  rmse.1se    = rep(0,ns),
 				  rmse.mrash1 = rep(0,ns),
				  rmse.mrash2 = rep(0,ns))
```

*Add text here describing how the simulations are implemented, and
 what is done in each iteration.*

```{r run-sims, warning=FALSE}
for (i in 1:ns) {
  cat(i,"")
  set.seed(i)
  p1    <- res[i,"p1"]
  dat   <- simulate_data(n,p,p1,pve)
  X     <- dat$X
  y     <- dat$y
  Xtest <- dat$Xtest
  ytest <- dat$ytest
  b     <- dat$b
  fit.glmnet <- cv.glmnet(X,y,alpha = 0.95,standardize = FALSE)
  b.glmnet   <- coef(fit.glmnet,s = "lambda.min")[-1]
  y1         <- drop(predict(fit.glmnet,dat$X,s = "lambda.min"))
  s          <- var(y - y1)
  fit.mrash1 <- mr.ash(X,y,standardize = FALSE)
  fit.mrash2 <- mr.ash(X,y,beta.init = b.glmnet,sigma2 = s)
  y.true     <- drop(Xtest %*% b)
  y.min      <- drop(predict(fit.glmnet,Xtest,s = "lambda.min"))
  y.1se      <- drop(predict(fit.glmnet,Xtest,s = "lambda.1se"))
  y.mrash1   <- predict(fit.mrash1,Xtest)
  y.mrash2   <- predict(fit.mrash2,Xtest)
  res[i,"rmse.true"]   <- sqrt(mean((ytest - y.true)^2))
  res[i,"rmse.min"]    <- sqrt(mean((ytest - y.min)^2))
  res[i,"rmse.1se"]    <- sqrt(mean((ytest - y.1se)^2))
  res[i,"rmse.mrash1"] <- sqrt(mean((ytest - y.mrash1)^2))
  res[i,"rmse.mrash2"] <- sqrt(mean((ytest - y.mrash2)^2))
}
cat("\n")
```

Create a scatterplot comparing the accuracy of the mr.ash estimates
against the glmnet estimates.

```{r}
plot1 <- ggplot(res,aes(x = rmse.min/rmse.true,y = rmse.1se/rmse.true,
                        fill = p1)) +
  geom_point(size = 2,shape = 21,color = "white") +
  geom_abline(slope = 1,intercept = 0,color = "black",linetype = "dotted") +
  scale_fill_gradient2(low = "lightskyblue",mid = "gold",high = "orangered",
                       midpoint = 250) +
  labs(x = "glmnet (\u03bb = \"min\")",
       y = "glmnet (\u03bb = \"1se\")") +
  theme_cowplot(12)
```

```{r}
plot2 <- ggplot(res,aes(x = rmse.min/rmse.true,y = rmse.mrash2/rmse.true,
                        fill = p1)) +
  geom_point(size = 2,shape = 21,color = "white") +
  geom_abline(slope = 1,intercept = 0,color = "black",linetype = "dotted") +
  scale_fill_gradient2(low = "lightskyblue",mid = "gold",high = "orangered",
                       midpoint = 250) +
  labs(x = "glmnet (\u03bb = min)",
       y = "mr.ash (lasso init)") +
  theme_cowplot(12)
```

```{r}
plot3 <- ggplot(res,aes(x = rmse.mrash1/rmse.true,y = rmse.mrash2/rmse.true,
                        fill = p1)) +
  geom_point(size = 2,shape = 21,color = "white") +
  geom_abline(slope = 1,intercept = 0,color = "black",linetype = "dotted") +
  scale_fill_gradient2(low = "lightskyblue",mid = "gold",high = "orangered",
                       midpoint = 250) +
  labs(x = "mr.ash",y = "mr.ash (lasso init)") +
  theme_cowplot(12)
```

Look at one example in greater detail.

```{r, eval=FALSE}
set.seed(15)
p1    <- 467
dat   <- simulate_data(n,p,p1,pve)
X     <- dat$X
y     <- dat$y
Xtest <- dat$Xtest
ytest <- dat$ytest
fit.glmnet <- cv.glmnet(X,y,alpha = 0.95,standardize = FALSE)
fit.mrash1 <- mr.ash(X,y,standardize = FALSE)
fit.mrash2 <- varbvsmix(X,NULL,y,update.w = FALSE,
                        sa = c(0,1/80),w = c(0.5,0.5))
fit.mrash3 <- varbvsmix(X,NULL,y,update.w = TRUE,
                        sa = c(0,1/200),w = c(0.5,0.5),
						alpha = fit.mrash2$alpha,mu = fit.mrash2$mu,
						drop.threshold = 0)
y.min      <- drop(predict(fit.glmnet,Xtest,s = "lambda.min"))
y.mrash1   <- predict(fit.mrash1,Xtest)
y.mrash2   <- predict(fit.mrash2,Xtest)
y.mrash3   <- predict(fit.mrash3,Xtest)
print(sqrt(mean((ytest - y.min)^2)))
print(sqrt(mean((ytest - y.mrash1)^2)))
print(sqrt(mean((ytest - y.mrash2)^2)))
print(sqrt(mean((ytest - y.mrash3)^2)))
qplot(coef(fit.glmnet,s = "lambda.min")[-1],fit.mrash1$beta) +
  theme_cowplot(12)
qplot(coef(fit.glmnet,s = "lambda.min")[-1],fit.mrash2$beta) +
  theme_cowplot(12)
```
